language: bash

# Free Travis gives max 5 concurrent builds
env:
  global:
  - IMAGE_NAME=${DOCKER_USERNAME}/spark
  - HADOOP_MAJMIN_VERSION=2.7
  - JAVA_MAJOR_VERSION=8
  - N=5

# Spark version is derived at runtime dynamically
matrix:
  include:
  # Debian builds
  - services: docker
    env:
    - DIST=debian
    - IDX=1
  - services: docker
    env:
    - DIST=debian
    - IDX=2
  - services: docker
    env:
    - DIST=debian
    - IDX=3
  - services: docker
    env:
    - DIST=debian
    - IDX=4
  - services: docker
    env:
    - DIST=debian
    - IDX=0
  # Alpine builds
  - services: docker
    env:
    - DIST=alpine
    - IDX=1
  - services: docker
    env:
    - DIST=alpine
    - IDX=2
  - services: docker
    env:
    - DIST=alpine
    - IDX=3
  - services: docker
    env:
    - DIST=alpine
    - IDX=4
  - services: docker
    env:
    - DIST=alpine
    - IDX=0
  
before_script:
- docker login -u="${DOCKER_USERNAME}" -p="${DOCKER_PASSWORD}"

script:
# Define static tags for referencing
- REF_TAG="ref"
- REF_IMAGE="${IMAGE_NAME}:${REF_TAG}"
- JAVA_MAJOR_TAG="java-${JAVA_MAJOR_VERSION}"
- DIST_TAG="${DIST}"

# Get all Spark versions first
- |-
  SPARK_ALL_VERSIONS_RAW=$(
    curl -s https://archive.apache.org/dist/spark/ |
    grep -oE 'spark-[2]\.[[:digit:]]+\.[[:digit:]]/' |
    grep -oE '[2]\.[[:digit:]]+\.[[:digit:]]' |
    sort | uniq)
- SPARK_ALL_VERSIONS=(${SPARK_ALL_VERSIONS_RAW})

# Get the array of major version
- SPARK_MAJ_VERSIONS=()
- |-
  for SPARK_VERSION in "${SPARK_ALL_VERSIONS[@]}"; do
    SPARK_MAJ_VERSION=${SPARK_VERSION:0:3}
    SPARK_MAJ_VERSIONS+=(${SPARK_MAJ_VERSION})
  done
- SPARK_MAJ_VERSIONS=($(echo "${SPARK_MAJ_VERSIONS[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))

# Get the array of Spark versions that contribute to the latest minor versions
- SPARK_VERSIONS_WITH_LATEST_MINOR=()
- |-
  for SPARK_MAJ_VERSION in "${SPARK_MAJ_VERSIONS[@]}"; do
    for SPARK_VERSION in "${SPARK_ALL_VERSIONS[@]}"; do
      if [[ ${SPARK_VERSION} == ${SPARK_MAJ_VERSION}* ]]; then
        # Because the version values are sorted in ascending order
        # The last value to match the major version is the latest version to use
        SPARK_SELECTED_VERSION=${SPARK_VERSION}
      fi
    done
    SPARK_VERSIONS_WITH_LATEST_MINOR+=(${SPARK_SELECTED_VERSION})
  done
- SPARK_VERSIONS_WITH_LATEST_MINOR=($(echo "${SPARK_VERSIONS_WITH_LATEST_MINOR[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))

- |-
  for SPARK_VERSION_WITH_LATEST_MINOR in "${SPARK_VERSIONS_WITH_LATEST_MINOR[@]}"; do
    echo ${SPARK_VERSION_WITH_LATEST_MINOR}
  done

# Get the array of Spark versions to build concurrently based on indexing
- SPARK_VERSIONS=($(echo "${SPARK_ALL_VERSIONS_RAW[@]}" | tr '\n' ' ' | awk "NR % ${N} == ${IDX}"))

# Iterate across each Spark version
- |-
  for SPARK_VERSION in "${SPARK_VERSIONS[@]}"; do
    echo Building Spark version - ${SPARK_VERSION}

    ## Check if current Spark version contributes to the latest minor version
    SPARK_VERSION_HAS_LATEST_MINOR=false

    for SPARK_VERSION_WITH_LATEST_MINOR in "${SPARK_VERSIONS_WITH_LATEST_MINOR[@]}"; do
      if [[ "${SPARK_VERSION}" == "${SPARK_VERSION_WITH_LATEST_MINOR}" ]]; then
        SPARK_VERSION_HAS_LATEST_MINOR=true
      fi
    done

    echo ${SPARK_VERSION} has latest minor version - ${SPARK_VERSION_HAS_LATEST_MINOR}

    ## Spark only tags
    SPARK_TAG="${SPARK_VERSION}"
    SPARK_MAJMIN_TAG="${SPARK_VERSION:0:3}"

    ## Spark + Java tags
    SPARK_JAVA_MAJOR_TAG="${SPARK_TAG}_${JAVA_MAJOR_TAG}"
    SPARK_MAJMIN_JAVA_MAJOR_TAG="${SPARK_MAJMIN_TAG}_${JAVA_MAJOR_TAG}"

    ## Spark + Dist tags
    SPARK_DIST_TAG="${SPARK_TAG}_${DIST_TAG}"
    SPARK_MAJMIN_DIST_TAG="${SPARK_MAJMIN_TAG}_${DIST_TAG}"

    ## Spark + Java + Dist tags
    SPARK_JAVA_MAJOR_DIST_TAG="${SPARK_TAG}_${JAVA_MAJOR_TAG}_${DIST_TAG}"
    SPARK_MAJMIN_JAVA_MAJOR_DIST_TAG="${SPARK_MAJMIN_TAG}_${JAVA_MAJOR_TAG}_${DIST_TAG}"

    # Docker build
    docker build . -f Dockerfile-${DIST} \
      --build-arg JAVA_MAJOR_VERSION="${JAVA_MAJOR_VERSION}" \
      --build-arg SPARK_VERSION="${SPARK_VERSION}" \
      --build-arg HADOOP_MAJMIN_VERSION="${HADOOP_MAJMIN_VERSION}" \
      -t "${REF_IMAGE}"

    # Docker verification
    docker run --rm -t ${REF_IMAGE} \
      spark-submit --version | grep "${SPARK_VERSION}" > /dev/null

    # Docker re-tagging
    # Spark version is always unique across Nomad version, so all builds can tag and push independently
    if [ "${DIST}" = "debian" ]; then
      # Non-dist tag is given to Debian
      docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_TAG}"
      docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_JAVA_MAJOR_TAG}"

      if [ "${SPARK_VERSION_HAS_LATEST_MINOR}" = "true" ]; then
        docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_MAJMIN_TAG}"
        docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_MAJMIN_JAVA_MAJOR_TAG}"
      fi
    fi

    # Common tags to all dists
    docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_DIST_TAG}"
    docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_JAVA_MAJOR_DIST_TAG}"

    if [ "${SPARK_VERSION_HAS_LATEST_MINOR}" = "true" ]; then
      docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_MAJMIN_DIST_TAG}"
      docker tag "${REF_IMAGE}" "${IMAGE_NAME}:${SPARK_MAJMIN_JAVA_MAJOR_DIST_TAG}"
    fi

    # Docker push to registry
    if [ "${TRAVIS_PULL_REQUEST}" = "false" ]; then
      if [ "${DIST} = debian" ]; then
        docker push "${IMAGE_NAME}:${SPARK_TAG}"
        docker push "${IMAGE_NAME}:${SPARK_JAVA_MAJOR_TAG}"

        if [ "${SPARK_VERSION_HAS_LATEST_MINOR}" = "true" ]; then
          docker push "${IMAGE_NAME}:${SPARK_MAJMIN_TAG}"
          docker push "${IMAGE_NAME}:${SPARK_MAJMIN_JAVA_MAJOR_TAG}"
        fi
      fi

      docker push "${IMAGE_NAME}:${SPARK_DIST_TAG}"
      docker push "${IMAGE_NAME}:${SPARK_JAVA_MAJOR_DIST_TAG}"

      if [ "${SPARK_VERSION_HAS_LATEST_MINOR}" = "true" ]; then
        docker push "${IMAGE_NAME}:${SPARK_MAJMIN_DIST_TAG}"
        docker push "${IMAGE_NAME}:${SPARK_MAJMIN_JAVA_MAJOR_DIST_TAG}"
      fi
    fi
  done

branches:
  only:
  - master
